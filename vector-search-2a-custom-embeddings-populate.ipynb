{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Populating Embedding Vectors in Mondodb Atlas\n",
    "\n",
    "We are going to create embedding attributes for movies collection.\n",
    "\n",
    "We will be using locally generated embeddings (no API calls)\n",
    "\n",
    "## References\n",
    "\n",
    "- https://docs.llamaindex.ai/en/stable/examples/embeddings/huggingface.html#huggingfaceembedding\n",
    "- Embedding models leaderboard : https://huggingface.co/spaces/mteb/leaderboard\n",
    "- Explaining leaderboard: https://huggingface.co/blog/mteb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using CUDA/GPU:  True\n",
      "device  0 NVIDIA GeForce RTX 2070\n"
     ]
    }
   ],
   "source": [
    "## Check if GPU is enabled\n",
    "import os\n",
    "import torch\n",
    "\n",
    "## To disable GPU and experiment, uncomment the following line\n",
    "## Normally, you would want to use GPU, if one is available.\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "\n",
    "print (\"using CUDA/GPU: \", torch.cuda.is_available())\n",
    "\n",
    "for i in range(torch.cuda.device_count()):\n",
    "   print(\"device \", i , torch.cuda.get_device_properties(i).name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup logging.  To see more loging set the level to DEBUG\n",
    "\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "# logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-1: Load Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Settings from .env file\n",
    "from dotenv import find_dotenv, dotenv_values\n",
    "\n",
    "# _ = load_dotenv(find_dotenv()) # read local .env file\n",
    "config = dotenv_values(find_dotenv())\n",
    "\n",
    "# debug\n",
    "# print (config)\n",
    "\n",
    "ATLAS_URI = config.get('ATLAS_URI')\n",
    "\n",
    "if not ATLAS_URI:\n",
    "    raise Exception (\"'ATLAS_URI' is not set.  Please set it above to continue...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our variables\n",
    "\n",
    "DB_NAME = 'sample_mflix'\n",
    "COLLECTION_NAME = 'embedded_movies'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-2: Initialize Mongo Atlas Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to the Mongo Atlas database!\n"
     ]
    }
   ],
   "source": [
    "from AtlasClient import AtlasClient\n",
    "\n",
    "atlas_client = AtlasClient (ATLAS_URI, DB_NAME)\n",
    "print(\"Connected to the Mongo Atlas database!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document count = 3,483\n"
     ]
    }
   ],
   "source": [
    "collection = atlas_client.get_collection(COLLECTION_NAME)\n",
    "document_count = collection.count_documents({})\n",
    "\n",
    "print (f\"document count = {document_count:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-3: Calculate Embeddings\n",
    "\n",
    "We are going to generate all embeddings locally on our computer, using open source models.  No API calls or API KEYS needed ! ðŸ˜„\n",
    "\n",
    "**Let's try a few embedding models**\n",
    "\n",
    "Here are a select models for comparison.  Taken from leaderboard : https://huggingface.co/spaces/mteb/leaderboard\n",
    "\n",
    "| model name                              | overall score | model size | model params | embedding length | License  | url                                                            |\n",
    "|-----------------------------------------|---------------|------------|--------------|------------------|----------|----------------------------------------------------------------|\n",
    "| intfloat/e5-mistral-7b-instruct         | 66.x          | 15 GB      | 7.11 B       | 4096             | MIT      | https://huggingface.co/intfloat/e5-mistral-7b-instruct         |\n",
    "| BAAI/bge-large-en-v1.5                  | 64.x          | 1.34 GB    | 335 M        | 1024             | MIT      | https://huggingface.co/BAAI/bge-large-en-v1.5                  |\n",
    "| BAAI/bge-small-en-v1.5                  | 62.x          | 133 MB     | 33.5 M       | 384              | MIT      | https://huggingface.co/BAAI/bge-small-en-v1.5                  |\n",
    "| sentence-transformers/all-mpnet-base-v2 | 57.8          | 438 MB     |              | 768              | Apache 2 | https://huggingface.co/sentence-transformers/all-mpnet-base-v2 |\n",
    "| sentence-transformers/all-MiniLM-L12-v2 | 56.x          | 134 MB     |              | 384              | Apache 2 | https://huggingface.co/sentence-transformers/all-MiniLM-L12-v2 |\n",
    "| sentence-transformers/all-MiniLM-L6-v2  | 56.x          | 91 MB      |              | 384              | Apache 2 | https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "## LlamaIndex will download embeddings models as needed.\n",
    "## Set llamaindex cache dir to ./cache dir here (Default is system tmp)\n",
    "## This way, we can easily see downloaded artifacts\n",
    "os.environ['LLAMA_INDEX_CACHE_DIR'] = os.path.join(os.path.abspath(''), 'cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings import HuggingFaceEmbedding\n",
    "import time\n",
    "\n",
    "## handy function to calculate embeddings, given a model\n",
    "def create_embeddings (movies, embedding_model, embedding_attr):\n",
    "    embed_model = HuggingFaceEmbedding(model_name=embedding_model)\n",
    "\n",
    "    t2a = time.perf_counter()\n",
    "    for movie in movies:\n",
    "        movie[embedding_attr] = embed_model.get_text_embedding(movie['plot'])\n",
    "\n",
    "    t2b = time.perf_counter()\n",
    "    # print (f'Embeddings generated for {len(movies):,} movies  in {(t2b-t2a)*1000:,.0f} ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 3,403 from Atlas in 14,260 ms\n"
     ]
    }
   ],
   "source": [
    "# fetch all movies\n",
    "t1a = time.perf_counter()\n",
    "movies = [m for m in atlas_client.find (collection_name=COLLECTION_NAME, filter={'plot':{\"$exists\": True}}, limit=0)]\n",
    "t1b = time.perf_counter()\n",
    "\n",
    "print (f'Fetched {len(movies):,} from Atlas in {(t1b-t1a)*1000:,.0f} ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Embedding models we want to use.\n",
    "\n",
    "model_mappings = {\n",
    "    'BAAI/bge-small-en-v1.5' : {'embedding_attr' : 'plot_embedding_bge_small', 'index_name' : 'idx_plot_embedding_bge_small'},\n",
    "\n",
    "    'sentence-transformers/all-mpnet-base-v2' : {'embedding_attr' : 'plot_embedding_mpnet_base_v2', 'index_name' : 'idx_plot_embedding_mpnet_base_v2'},\n",
    "\n",
    "    # 'sentence-transformers/all-MiniLM-L12-v2' : {'embedding_attr' : 'plot_embedding_minilm_l12_v2', 'index_name' : 'idx_plot_embedding_minilm_l12_v2'},\n",
    "\n",
    "    'sentence-transformers/all-MiniLM-L6-v2' : {'embedding_attr' : 'plot_embedding_minilm_l6_v2', 'index_name' : 'idx_plot_embedding_minilm_l6_v2'},\n",
    "\n",
    "    ## bge-large takes too long and consumes too much memory!\n",
    "    # 'BAAI/bge-large-en-v1.5' : {'embedding_attr' : 'plot_embedding_bge_large', 'index_name' : 'idx_plot_embedding_bge_large', 'embedding_length' : 1024},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------- embedding model = BAAI/bge-small-en-v1.5 ---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sujee/anaconda3/envs/atlas-2/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model=BAAI/bge-small-en-v1.5, created embeddings for 3,403 movies in 33,073 ms, avg_time_per_movie=10 ms\n",
      "\n",
      "------- embedding model = sentence-transformers/all-mpnet-base-v2 ---------\n",
      "model=sentence-transformers/all-mpnet-base-v2, created embeddings for 3,403 movies in 25,875 ms, avg_time_per_movie=8 ms\n",
      "\n",
      "------- embedding model = sentence-transformers/all-MiniLM-L6-v2 ---------\n",
      "model=sentence-transformers/all-MiniLM-L6-v2, created embeddings for 3,403 movies in 13,702 ms, avg_time_per_movie=4 ms\n"
     ]
    }
   ],
   "source": [
    "## For selected embedding models above, we are giong to create vectors\n",
    "## in movie collection.\n",
    "## Remember, each embedding model has its own 'plot_embedding' attribute (we don't want to mix them up)\n",
    "\n",
    "for key in model_mappings.keys():\n",
    "    embedding_model = key\n",
    "    embedding_attr = model_mappings[key]['embedding_attr']\n",
    "\n",
    "    print (f'\\n------- embedding model = {embedding_model} ---------')\n",
    "    t1a = time.perf_counter()\n",
    "    create_embeddings(movies=movies, embedding_model=embedding_model, embedding_attr=embedding_attr)\n",
    "    t1b = time.perf_counter()\n",
    "    avg_time_per_movie = (t1b-t1a)*1000 / len(movies)\n",
    "    print (f'model={embedding_model}, created embeddings for {len(movies):,} movies in {(t1b-t1a)*1000:,.0f} ms, avg_time_per_movie={avg_time_per_movie:,.0f} ms')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-4: Inspect Generated Embeddings\n",
    "\n",
    "Run the cell below a few times to see a different movie each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_id : 573a1399f29313caabced644\n",
      "title : Unforgiven\n",
      "plot : Retired Old West gunslinger William Munny reluctantly takes on one last job, with the help of his old partner and a young man.\n",
      "plot_embeddings (existing openAI generated), len=1536 , [-0.015232798, -0.024966672, -0.0036355436, -0.008456874, -0.021839323]...\n",
      "plot_embedding_bge_small , len=384 , [-0.04438990354537964, 0.036243874579668045, 0.037500377744436264, -0.0010036976309493184, 0.0009061899036169052]...\n",
      "plot_embedding_mpnet_base_v2 , len=768 , [-0.0023269052617251873, 0.1270730048418045, 0.033072661608457565, -0.005018125753849745, -0.037151169031858444]...\n",
      "plot_embedding_minilm_l6_v2 , len=384 , [-0.03493762016296387, -0.008418717421591282, -0.004047343973070383, 0.01668776012957096, 0.015404606238007545]...\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "movie = random.choice(movies)\n",
    "# print (movie)\n",
    "print ('_id :', movie['_id'])\n",
    "print ('title :', movie['title'])\n",
    "print ('plot :', movie['plot'])\n",
    "print (f'plot_embeddings (existing openAI generated), len={len(movie[\"plot_embedding\"])} , {movie[\"plot_embedding\"][:5]}...')\n",
    "print (f'plot_embedding_bge_small , len={len(movie[\"plot_embedding_bge_small\"])} , {movie[\"plot_embedding_bge_small\"][:5]}...')\n",
    "print (f'plot_embedding_mpnet_base_v2 , len={len(movie[\"plot_embedding_mpnet_base_v2\"])} , {movie[\"plot_embedding_mpnet_base_v2\"][:5]}...')\n",
    "print (f'plot_embedding_minilm_l6_v2 , len={len(movie[\"plot_embedding_minilm_l6_v2\"])} , {movie[\"plot_embedding_minilm_l6_v2\"][:5]}...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-5: Now Update Movie Collection in Atlas\n",
    "\n",
    "We have calculated all embeddings locally.\n",
    "\n",
    "Let's update the Atlas database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If we update documents ONE-BY-ONE, it takes about 5 minutes to complete\n",
    "## So this code is not recommended\n",
    "\n",
    "\n",
    "# collection = atlas_client.get_collection(COLLECTION_NAME)\n",
    "\n",
    "# t1a = time.perf_counter()\n",
    "# for movie in movies:\n",
    "# \tcollection.replace_one({'_id': movie['_id']}, movie)\n",
    "# t1b = time.perf_counter()\n",
    "\n",
    "# print (f'Updated {len(movies):,} in Atlas in {(t1b-t1a)*1000:,.0f} ms')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About to update 3403 movies in Atlas...\n",
      "Update matched count: 3403\n",
      "Update modified count: 0\n",
      "Updated 3,403 in Atlas in 70,850 ms\n"
     ]
    }
   ],
   "source": [
    "## Let's do a bulk update\n",
    "from pymongo import  ReplaceOne\n",
    "\n",
    "\n",
    "collection = atlas_client.get_collection(COLLECTION_NAME)\n",
    "\n",
    "replacements = [ReplaceOne ({\"_id\" : movie[\"_id\"]}, movie) for movie in movies]\n",
    "\n",
    "# print (replacements[:3])\n",
    "\n",
    "# Perform bulk replacement\n",
    "print (f'About to update {len(replacements)} movies in Atlas...')\n",
    "t1a = time.perf_counter()\n",
    "result = collection.bulk_write(replacements)\n",
    "t1b = time.perf_counter()\n",
    "\n",
    "## Print result\n",
    "print(f\"Update matched count: {result.matched_count}\")\n",
    "print(f\"Update modified count: {result.modified_count}\")\n",
    "print (f'Updated {len(movies):,} in Atlas in {(t1b-t1a)*1000:,.0f} ms')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-6: Verify Data in Atlas UI\n",
    "\n",
    "Let's see if the embeddings are populuated in Atlas.\n",
    "\n",
    "Go to Atlas UI --> Browse Collections --> sample_mflix --> embedded_movies\n",
    "\n",
    "You should see something like this:\n",
    "\n",
    "![](images/custom-embeddings-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-7: Create Indexes\n",
    "\n",
    "We need to create indexes on embedding attributes before we query.\n",
    "\n",
    "Refer to this document for detailed steps : [setup-atlas-index.md](setup-atlas-index.md)\n",
    "\n",
    "Remember, we have a few embeddings, each needs its own index.\n",
    "\n",
    "We have have 3 indices in Atlas in free tier.  So we can create additional 2 indexes. That is perfectly ok for this lab.  You can choose which ones to experiment with.\n",
    "\n",
    "**In Atlas UI, enter the index commands below correctly.  Make sure `path` and `numDimensions` match!**\n",
    "\n",
    "![](images/atlas-index-5.png)\n",
    "\n",
    "\n",
    "### Embedding-1: `BAAI/bge-small-en-v1.5`\n",
    "\n",
    "Index type: **Atlas Vector Search**\n",
    "\n",
    "Index name: **`idx_plot_embedding_bge_small`**\n",
    "\n",
    "**Index definition**\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"type\": \"vector\",\n",
    "      \"path\": \"plot_embedding_bge_small\",\n",
    "      \"numDimensions\": 384,\n",
    "      \"similarity\": \"euclidean\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "### Embedding-2: `sentence-transformers/all-mpnet-base-v2`\n",
    "\n",
    "Index type: **Atlas Vector Search**\n",
    "\n",
    "Index name: **`idx_plot_embedding_mpnet_base_v2`**\n",
    "\n",
    "**Index definition**\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"type\": \"vector\",\n",
    "      \"path\": \"plot_embedding_mpnet_base_v2\",\n",
    "      \"numDimensions\": 768,\n",
    "      \"similarity\": \"euclidean\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "### (Optional) Embedding-3: `sentence-transformers/all-MiniLM-L6-v2`\n",
    "\n",
    "Index type: **Atlas Vector Search**\n",
    "\n",
    "Index name: **`idx_plot_embedding_minilm_l6_v2`**\n",
    "\n",
    "**Index definition**\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"type\": \"vector\",\n",
    "      \"path\": \"plot_embedding_minilm_l6_v2\",\n",
    "      \"numDimensions\": 384,\n",
    "      \"similarity\": \"euclidean\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-8: Verifying Indexes\n",
    "\n",
    "Make sure indexes are ready and active before proceeding to the next step.\n",
    "\n",
    "![](images/index-verify.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atlas-1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
