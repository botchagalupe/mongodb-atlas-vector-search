{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBO7SUBEkka-"
      },
      "source": [
        "# Test Open AI Access\n",
        "\n",
        "Check that your API key is working\n",
        "\n",
        "Run this on Colab : \n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sujee/mongodb-atlas-vector-search/blob/main/test-openai.ipynb)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-3fLiiZElJpp"
      },
      "outputs": [],
      "source": [
        "import os, sys\n",
        "import pprint\n",
        "import json\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6GJzby9kpHR"
      },
      "source": [
        "## Runing on Colab?\n",
        "\n",
        "The next will tell you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HBhxgjDlIEx",
        "outputId": "018c3cdb-468c-499b-8cf2-f6108bb93357"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NOT in Colab\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
        "   print(\"Running in Colab\")\n",
        "   RUNNING_IN_COLAB = True\n",
        "else:\n",
        "   print(\"NOT in Colab\")\n",
        "   RUNNING_IN_COLAB = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "if you are running on COLAB, uncomment the following cell and execute.\n",
        "\n",
        "We only have to do it once"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N19Zmpu5kvNA",
        "outputId": "310a0f0f-e6f8-495e-e304-766fd73332d7"
      },
      "outputs": [],
      "source": [
        "# !pip install --upgrade openai  python-dotenv\n",
        "# !pip show openai | grep Version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tevhVgHQkkbA"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv, find_dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DO89XuWOkkbC"
      },
      "source": [
        "## Load Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5heg6ZxwkkbC",
        "outputId": "2f21495c-668f-4b53-a9b3-3f0042aa7101"
      },
      "outputs": [],
      "source": [
        "## Load Settings from .env file\n",
        "\n",
        "_ = load_dotenv(find_dotenv()) # read local .env file\n",
        "\n",
        "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "## Manual override\n",
        "# OPENAI_API_KEY=\"abc123\"\n",
        "\n",
        "# print (\"OPENAI_API_KEY : \", OPENAI_API_KEY )\n",
        "\n",
        "\n",
        "if not OPENAI_API_KEY:\n",
        "    raise Exception (\"'OPENAI_API_KEY' is not set.  Please set it above to continue...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Let's Try Chat Completion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "MEzscp9okkbF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('{\\n'\n",
            " '    \"id\": \"chatcmpl-8VCXiMML0UBXKqDuNebW3tj7m6cZC\",\\n'\n",
            " '    \"choices\": [\\n'\n",
            " '        {\\n'\n",
            " '            \"finish_reason\": \"stop\",\\n'\n",
            " '            \"index\": 0,\\n'\n",
            " '            \"message\": {\\n'\n",
            " '                \"content\": \"This is a test.\",\\n'\n",
            " '                \"role\": \"assistant\",\\n'\n",
            " '                \"function_call\": null,\\n'\n",
            " '                \"tool_calls\": null\\n'\n",
            " '            }\\n'\n",
            " '        }\\n'\n",
            " '    ],\\n'\n",
            " '    \"created\": 1702447074,\\n'\n",
            " '    \"model\": \"gpt-3.5-turbo-0613\",\\n'\n",
            " '    \"object\": \"chat.completion\",\\n'\n",
            " '    \"system_fingerprint\": null,\\n'\n",
            " '    \"usage\": {\\n'\n",
            " '        \"completion_tokens\": 5,\\n'\n",
            " '        \"prompt_tokens\": 12,\\n'\n",
            " '        \"total_tokens\": 17\\n'\n",
            " '    }\\n'\n",
            " '}')\n"
          ]
        }
      ],
      "source": [
        "client = OpenAI(\n",
        "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "    api_key= os.environ.get(\"OPENAI_API_KEY\"),\n",
        ")\n",
        "\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Say this is a test\",\n",
        "        }\n",
        "    ],\n",
        "    model=\"gpt-3.5-turbo\",\n",
        ")\n",
        "\n",
        "pprint.pprint (chat_completion.model_dump_json(indent=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Check Embeddings\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# https://platform.openai.com/docs/guides/embeddings/what-are-embeddings\n",
        "\n",
        "def generate_embedding(text: str,  model=\"text-embedding-ada-002\") -> list[float]:\n",
        "    text = text.replace(\"\\n\", \" \")\n",
        "    resp = client.embeddings.create (\n",
        "\t\tinput=[text],\n",
        "\t\tmodel=model  )\n",
        "\n",
        "    return resp.data[0].embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding for word='apple' using model='text-embedding-ada-002', embeddding_length=1536, printing first few numbers... :\n",
            " [0.00777884665876627, -0.023069249466061592, -0.007360776886343956, -0.02774341218173504, -0.00457478454336524, 0.012891639955341816, -0.021863015368580818, -0.00858757272362709, 0.01892966963350773, -0.029854323714971542]\n"
          ]
        }
      ],
      "source": [
        "word = 'apple'\n",
        "model = 'text-embedding-ada-002'\n",
        "embedding = generate_embedding(word, model)\n",
        "print (f\"Embedding for word='{word}' using model='{model}', embeddding_length={len(embedding)}, printing first few numbers... :\\n\", embedding [:10] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding for word='apple' using model='text-similarity-babbage-001', embeddding_length=2048, printing first few numbers... :\n",
            " [0.010828019119799137, -0.002828809432685375, -0.00380324712023139, 0.017472675070166588, 0.018480714410543442, 0.00637164618819952, 0.010273597203195095, 0.006980670150369406, 0.006073434837162495, -0.03971673548221588]\n"
          ]
        }
      ],
      "source": [
        "word = 'apple'\n",
        "model = 'text-similarity-babbage-001'\n",
        "embedding = generate_embedding(word, model)\n",
        "print (f\"Embedding for word='{word}' using model='{model}', embeddding_length={len(embedding)}, printing first few numbers... :\\n\", embedding [:10] )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Visualizing Word Embeddings\n",
        "\n",
        "Here is a nice demo, where you can see how the words are mapped to embeddings\n",
        "\n",
        "https://projector.tensorflow.org/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "genai3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
