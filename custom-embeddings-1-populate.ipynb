{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Populating Embedding Vectors in Mondodb Atlas\n",
    "\n",
    "We are going to create embedding attributes for movies collection.\n",
    "\n",
    "We will be using locally generated embeddings (no API calls)\n",
    "\n",
    "## References\n",
    "\n",
    "- https://docs.llamaindex.ai/en/stable/examples/embeddings/huggingface.html#huggingfaceembedding\n",
    "- Leaderboard : https://huggingface.co/spaces/mteb/leaderboard\n",
    "- Explaining leaderboard: https://huggingface.co/blog/mteb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "## Load Settings from .env file\n",
    "from dotenv import find_dotenv, dotenv_values\n",
    "\n",
    "# _ = load_dotenv(find_dotenv()) # read local .env file\n",
    "config = dotenv_values(find_dotenv())\n",
    "\n",
    "# debug\n",
    "# print (config)\n",
    "\n",
    "ATLAS_URI = config.get('ATLAS_URI')\n",
    "\n",
    "if not ATLAS_URI:\n",
    "    raise Exception (\"'ATLAS_URI' is not set.  Please set it above to continue...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our variables\n",
    "\n",
    "DB_NAME = 'sample_mflix'\n",
    "COLLECTION_NAME = 'embedded_movies'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find My Public IP\n",
    "\n",
    "This IP address should be added to Atlas's 'access list' for the connection to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# ip = requests.get('https://api.ipify.org').text()\n",
    "\n",
    "from urllib.request import urlopen\n",
    "ip = urlopen('https://api.ipify.org').read()\n",
    "print (f\"My public IP is '{ip}.   Make sure this IP is allowed to connect to cloud Atlas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Mongo Atlas Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AtlasClient import AtlasClient\n",
    "\n",
    "atlas_client = AtlasClient (ATLAS_URI, DB_NAME)\n",
    "print(\"Connected to the Mongo Atlas database!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = atlas_client.get_collection(COLLECTION_NAME)\n",
    "document_count = collection.count_documents({})\n",
    "\n",
    "print (f\"document count = {document_count:,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Embeddings\n",
    "\n",
    "We are going to generate all embeddings locally on our computer, using open source models.  No API calls or API KEYS needed ! ðŸ˜„\n",
    "\n",
    "**Let's try a few embedding models**\n",
    "\n",
    "Here are a select models for comparison.  Taken from leaderboard : https://huggingface.co/spaces/mteb/leaderboard\n",
    "\n",
    "| model name                              | overall score | model params | model size | embedding length | url                                                            |\n",
    "|-----------------------------------------|---------------|--------------|------------|------------------|----------------------------------------------------------------|\n",
    "| intfloat/e5-mistral-7b-instruct         | 66.x          | 7.11 B       | 15 GB      | 4096             | https://huggingface.co/intfloat/e5-mistral-7b-instruct         |\n",
    "| BAAI/bge-large-en-v1.5                  | 64.x          | 335 M        | 1.34 GB    | 1024             | https://huggingface.co/BAAI/bge-large-en-v1.5                  |\n",
    "| BAAI/bge-small-en-v1.5                  | 62.x          | 33.5 M       | 133 MB     | 384              | https://huggingface.co/BAAI/bge-small-en-v1.5                  |\n",
    "| sentence-transformers/all-mpnet-base-v2 | 57.8          |              | 438 MB     | 768              | https://huggingface.co/sentence-transformers/all-mpnet-base-v2 |\n",
    "| sentence-transformers/all-MiniLM-L12-v2 | 56.x          |              | 134 MB     | 384              | https://huggingface.co/sentence-transformers/all-MiniLM-L12-v2 |\n",
    "| sentence-transformers/all-MiniLM-L6-v2  | 56.x          |              | 91 MB      | 384              | https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "## LlamaIndex will download embeddings models as needed.\n",
    "## Set llamaindex cache dir to ./cache dir here (Default is system tmp)\n",
    "## This way, we can easily see downloaded artifacts\n",
    "os.environ['LLAMA_INDEX_CACHE_DIR'] = os.path.join(os.path.abspath(''), 'cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings import HuggingFaceEmbedding\n",
    "import time\n",
    "\n",
    "## handy function to calculate embeddings, given a model\n",
    "def create_embeddings (movies, embedding_model, embedding_attr):\n",
    "    embed_model = HuggingFaceEmbedding(model_name=embedding_model)\n",
    "\n",
    "    t2a = time.perf_counter()\n",
    "    for movie in movies:\n",
    "        movie[embedding_attr] = embed_model.get_text_embedding(movie['plot'])\n",
    "\n",
    "    t2b = time.perf_counter()\n",
    "    # print (f'Embeddings generated for {len(movies):,} movies  in {(t2b-t2a)*1000:,.0f} ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch all movies\n",
    "t1a = time.perf_counter()\n",
    "movies = [m for m in atlas_client.find (collection_name=COLLECTION_NAME, filter={'plot':{\"$exists\": True}}, limit=0)]\n",
    "t1b = time.perf_counter()\n",
    "\n",
    "print (f'Fetched {len(movies):,} from Atlas in {(t1b-t1a)*1000:,.0f} ms')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Embedding models we want to use.\n",
    "\n",
    "model_mappings = {\n",
    "    'BAAI/bge-small-en-v1.5' : {'embedding_attr' : 'plot_embedding_bge_small', 'index_name' : 'idx_plot_embedding_bge_small'},\n",
    "\n",
    "    'sentence-transformers/all-mpnet-base-v2' : {'embedding_attr' : 'plot_embedding_mpnet_base_v2', 'index_name' : 'idx_plot_embedding_mpnet_base_v2'},\n",
    "\n",
    "    # 'sentence-transformers/all-MiniLM-L12-v2' : {'embedding_attr' : 'plot_embedding_minilm_l12_v2', 'index_name' : 'idx_plot_embedding_minilm_l12_v2'},\n",
    "\n",
    "    'sentence-transformers/all-MiniLM-L6-v2' : {'embedding_attr' : 'plot_embedding_minilm_l6_v2', 'index_name' : 'idx_plot_embedding_minilm_l6_v2'},\n",
    "\n",
    "    ## bge-large takes too long and consumes too much memory!\n",
    "    # 'BAAI/bge-large-en-v1.5' : {'embedding_attr' : 'plot_embedding_bge_large', 'index_name' : 'idx_plot_embedding_bge_large', 'embedding_length' : 1024},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For selected embedding models above, we are giong to create vectors\n",
    "## in movie collection.\n",
    "## Remember, each embedding model has its own 'plot_embedding' attribute (we don't want to mix them up)\n",
    "\n",
    "for key in model_mappings.keys():\n",
    "    embedding_model = key\n",
    "    embedding_attr = model_mappings[key]['embedding_attr']\n",
    "\n",
    "    print (f'\\n------- embedding model = {embedding_model} ---------')\n",
    "    t1a = time.perf_counter()\n",
    "    create_embeddings(movies=movies, embedding_model=embedding_model, embedding_attr=embedding_attr)\n",
    "    t1b = time.perf_counter()\n",
    "    avg_time_per_movie = (t1b-t1a)*1000 / len(movies)\n",
    "    print (f'model={embedding_model}, created embeddings for {len(movies):,} movies in {(t1b-t1a)*1000:,.0f} ms, avg_time_per_movie={avg_time_per_movie:,.0f} ms')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inspect a random movie embeddings\n",
    "## Run this cell a few times to see a different movie each time\n",
    "import random\n",
    "\n",
    "movie = random.choice(movies)\n",
    "# print (movie)\n",
    "print ('_id :', movie['_id'])\n",
    "print ('title :', movie['title'])\n",
    "print ('plot :', movie['plot'])\n",
    "print (f'plot_embeddings (existing openAI generated), len={len(movie[\"plot_embedding\"])} , {movie[\"plot_embedding\"][:5]}...')\n",
    "print (f'plot_embedding_bge_small , len={len(movie[\"plot_embedding_bge_small\"])} , {movie[\"plot_embedding_bge_small\"][:5]}...')\n",
    "print (f'plot_embedding_mpnet_base_v2 , len={len(movie[\"plot_embedding_mpnet_base_v2\"])} , {movie[\"plot_embedding_mpnet_base_v2\"][:5]}...')\n",
    "print (f'plot_embedding_minilm_l6_v2 , len={len(movie[\"plot_embedding_minilm_l6_v2\"])} , {movie[\"plot_embedding_minilm_l6_v2\"][:5]}...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now Update Movie Collection in Atlas\n",
    "\n",
    "We have calculated all embeddings locally.\n",
    "\n",
    "Let's update the Atlas database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If we update documents ONE-BY-ONE, it takes about 5 minutes to complete\n",
    "## So this code is not recommended\n",
    "\n",
    "\n",
    "# collection = atlas_client.get_collection(COLLECTION_NAME)\n",
    "\n",
    "# t1a = time.perf_counter()\n",
    "# for movie in movies:\n",
    "# \tcollection.replace_one({'_id': movie['_id']}, movie)\n",
    "# t1b = time.perf_counter()\n",
    "\n",
    "# print (f'Updated {len(movies):,} in Atlas in {(t1b-t1a)*1000:,.0f} ms')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's do a bulk update\n",
    "from pymongo import  ReplaceOne\n",
    "\n",
    "\n",
    "collection = atlas_client.get_collection(COLLECTION_NAME)\n",
    "\n",
    "replacements = [ReplaceOne ({\"_id\" : movie[\"_id\"]}, movie) for movie in movies]\n",
    "\n",
    "# print (replacements[:3])\n",
    "\n",
    "# Perform bulk replacement\n",
    "print (f'About to update {len(replacements)} movies in Atlas...')\n",
    "t1a = time.perf_counter()\n",
    "result = collection.bulk_write(replacements)\n",
    "t1b = time.perf_counter()\n",
    "\n",
    "## Print result\n",
    "print(f\"Update matched count: {result.matched_count}\")\n",
    "print(f\"Update modified count: {result.modified_count}\")\n",
    "print (f'Updated {len(movies):,} in Atlas in {(t1b-t1a)*1000:,.0f} ms')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Indexes\n",
    "\n",
    "We need to create indexes on embedding attributes before we query.\n",
    "\n",
    "Refer to this document for detailed steps : [setup-atlas-index.md](setup-atlas-index.md)\n",
    "\n",
    "Remember, we have a few embeddings, each needs its own index.\n",
    "\n",
    "We have have 3 indices in Atlas in free tier.  So we can create additional 2 indexes. That is perfectly ok for this lab.  You can choose which ones to experiment with.\n",
    "\n",
    "**In Atlas UI, enter the index commands below correctly.  Make sure `path` and `numDimensions` match!**\n",
    "\n",
    "\n",
    "### Embedding-1: `BAAI/bge-small-en-v1.5`\n",
    "\n",
    "Index type: **Atlas Vector Search**\n",
    "\n",
    "Index name: **`idx_plot_embedding_bge_small`**\n",
    "\n",
    "**Index definition**\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"type\": \"vector\",\n",
    "      \"path\": \"plot_embedding_bge_small\",\n",
    "      \"numDimensions\": 384,\n",
    "      \"similarity\": \"euclidean\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "### Embedding-2: `sentence-transformers/all-mpnet-base-v2`\n",
    "\n",
    "Index type: **Atlas Vector Search**\n",
    "\n",
    "Index name: **`idx_plot_embedding_mpnet_base_v2`**\n",
    "\n",
    "**Index definition**\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"type\": \"vector\",\n",
    "      \"path\": \"plot_embedding_mpnet_base_v2\",\n",
    "      \"numDimensions\": 768,\n",
    "      \"similarity\": \"euclidean\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "### (Optional) Embedding-3: `sentence-transformers/all-MiniLM-L6-v2`\n",
    "\n",
    "Index type: **Atlas Vector Search**\n",
    "\n",
    "Index name: **`idx_plot_embedding_minilm_l6_v2`**\n",
    "\n",
    "**Index definition**\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"type\": \"vector\",\n",
    "      \"path\": \"plot_embedding_minilm_l6_v2\",\n",
    "      \"numDimensions\": 384,\n",
    "      \"similarity\": \"euclidean\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verifying Indexes\n",
    "\n",
    "Make sure indexes are ready and active before proceeding to the next step.\n",
    "\n",
    "![](images/index-verify.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atlas-1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
