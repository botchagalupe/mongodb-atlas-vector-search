{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Populating Embedding Vectors in Mondodb Atlas\n",
    "\n",
    "We are going to create embedding attributes for movies collection.\n",
    "\n",
    "We will be using locally generated embeddings (no API calls)\n",
    "\n",
    "## References\n",
    "\n",
    "- https://docs.llamaindex.ai/en/stable/examples/embeddings/huggingface.html#huggingfaceembedding\n",
    "- Embedding models leaderboard : https://huggingface.co/spaces/mteb/leaderboard\n",
    "- Explaining leaderboard: https://huggingface.co/blog/mteb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using CUDA/GPU:  True\n",
      "device  0 NVIDIA GeForce RTX 2070\n"
     ]
    }
   ],
   "source": [
    "## Check if GPU is enabled\n",
    "import os\n",
    "import torch\n",
    "\n",
    "## To disable GPU and experiment, uncomment the following line\n",
    "## Normally, you would want to use GPU, if one is available.\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "\n",
    "print (\"using CUDA/GPU: \", torch.cuda.is_available())\n",
    "\n",
    "for i in range(torch.cuda.device_count()):\n",
    "   print(\"device \", i , torch.cuda.get_device_properties(i).name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup logging.  To see more loging set the level to DEBUG\n",
    "\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "# logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "this_dir = os.path.abspath('')\n",
    "parent_dir = os.path.dirname(this_dir)\n",
    "sys.path.append (os.path.abspath (parent_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-1: Load Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Settings from .env file\n",
    "from dotenv import find_dotenv, dotenv_values\n",
    "\n",
    "# _ = load_dotenv(find_dotenv()) # read local .env file\n",
    "config = dotenv_values(find_dotenv())\n",
    "\n",
    "# debug\n",
    "# print (config)\n",
    "\n",
    "ATLAS_URI = config.get('ATLAS_URI')\n",
    "\n",
    "if not ATLAS_URI:\n",
    "    raise Exception (\"'ATLAS_URI' is not set.  Please set it above to continue...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our variables\n",
    "\n",
    "DB_NAME = 'sample_mflix'\n",
    "COLLECTION_NAME = 'embedded_movies'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-2: Initialize Mongo Atlas Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to the Mongo Atlas database!\n"
     ]
    }
   ],
   "source": [
    "from AtlasClient import AtlasClient\n",
    "\n",
    "atlas_client = AtlasClient (ATLAS_URI, DB_NAME)\n",
    "print(\"Connected to the Mongo Atlas database!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document count = 3,483\n"
     ]
    }
   ],
   "source": [
    "collection = atlas_client.get_collection(COLLECTION_NAME)\n",
    "document_count = collection.count_documents({})\n",
    "\n",
    "print (f\"document count = {document_count:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-3: Calculate Embeddings\n",
    "\n",
    "We are going to generate all embeddings locally on our computer, using open source models.  No API calls or API KEYS needed ! ðŸ˜„\n",
    "\n",
    "**Let's try a few embedding models**\n",
    "\n",
    "Here are a select models for comparison.  Taken from leaderboard : https://huggingface.co/spaces/mteb/leaderboard\n",
    "\n",
    "| model name                              | overall score | model size | model params | embedding length | License  | url                                                            |\n",
    "|-----------------------------------------|---------------|------------|--------------|------------------|----------|----------------------------------------------------------------|\n",
    "| intfloat/e5-mistral-7b-instruct         | 66.x          | 15 GB      | 7.11 B       | 4096             | MIT      | https://huggingface.co/intfloat/e5-mistral-7b-instruct         |\n",
    "| BAAI/bge-large-en-v1.5                  | 64.x          | 1.34 GB    | 335 M        | 1024             | MIT      | https://huggingface.co/BAAI/bge-large-en-v1.5                  |\n",
    "| BAAI/bge-small-en-v1.5                  | 62.x          | 133 MB     | 33.5 M       | 384              | MIT      | https://huggingface.co/BAAI/bge-small-en-v1.5                  |\n",
    "| sentence-transformers/all-mpnet-base-v2 | 57.8          | 438 MB     |              | 768              | Apache 2 | https://huggingface.co/sentence-transformers/all-mpnet-base-v2 |\n",
    "| sentence-transformers/all-MiniLM-L12-v2 | 56.x          | 134 MB     |              | 384              | Apache 2 | https://huggingface.co/sentence-transformers/all-MiniLM-L12-v2 |\n",
    "| sentence-transformers/all-MiniLM-L6-v2  | 56.x          | 91 MB      |              | 384              | Apache 2 | https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "## LlamaIndex will download embeddings models as needed.\n",
    "## Set llamaindex cache dir to ./cache dir here (Default is system tmp)\n",
    "## This way, we can easily see downloaded artifacts\n",
    "os.environ['LLAMA_INDEX_CACHE_DIR'] = os.path.join(os.path.abspath(''), '..', 'llama-index-cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings import HuggingFaceEmbedding\n",
    "import time\n",
    "\n",
    "## handy function to calculate embeddings, given a model\n",
    "def create_embeddings (movies, embedding_model, embedding_attr):\n",
    "    embed_model = HuggingFaceEmbedding(model_name=embedding_model)\n",
    "\n",
    "    t2a = time.perf_counter()\n",
    "    for movie in movies:\n",
    "        movie[embedding_attr] = embed_model.get_text_embedding(movie['plot'])\n",
    "\n",
    "    t2b = time.perf_counter()\n",
    "    # print (f'Embeddings generated for {len(movies):,} movies  in {(t2b-t2a)*1000:,.0f} ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 3,403 from Atlas in 9,716 ms\n"
     ]
    }
   ],
   "source": [
    "# fetch all movies\n",
    "t1a = time.perf_counter()\n",
    "movies = [m for m in atlas_client.find (collection_name=COLLECTION_NAME, filter={'plot':{\"$exists\": True}}, limit=0)]\n",
    "t1b = time.perf_counter()\n",
    "\n",
    "print (f'Fetched {len(movies):,} from Atlas in {(t1b-t1a)*1000:,.0f} ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Embedding models we want to use.\n",
    "\n",
    "model_mappings = {\n",
    "    'BAAI/bge-small-en-v1.5' : {'embedding_attr' : 'plot_embedding_bge_small', 'index_name' : 'idx_plot_embedding_bge_small'},\n",
    "\n",
    "    'sentence-transformers/all-mpnet-base-v2' : {'embedding_attr' : 'plot_embedding_mpnet_base_v2', 'index_name' : 'idx_plot_embedding_mpnet_base_v2'},\n",
    "\n",
    "    # 'sentence-transformers/all-MiniLM-L12-v2' : {'embedding_attr' : 'plot_embedding_minilm_l12_v2', 'index_name' : 'idx_plot_embedding_minilm_l12_v2'},\n",
    "\n",
    "    'sentence-transformers/all-MiniLM-L6-v2' : {'embedding_attr' : 'plot_embedding_minilm_l6_v2', 'index_name' : 'idx_plot_embedding_minilm_l6_v2'},\n",
    "\n",
    "    ## bge-large takes too long and consumes too much memory!\n",
    "    # 'BAAI/bge-large-en-v1.5' : {'embedding_attr' : 'plot_embedding_bge_large', 'index_name' : 'idx_plot_embedding_bge_large', 'embedding_length' : 1024},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------- embedding model = BAAI/bge-small-en-v1.5 ---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sujee/anaconda3/envs/atlas-2/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model=BAAI/bge-small-en-v1.5, created embeddings for 3,403 movies in 27,482 ms, avg_time_per_movie=8 ms\n",
      "\n",
      "------- embedding model = sentence-transformers/all-mpnet-base-v2 ---------\n",
      "model=sentence-transformers/all-mpnet-base-v2, created embeddings for 3,403 movies in 26,754 ms, avg_time_per_movie=8 ms\n",
      "\n",
      "------- embedding model = sentence-transformers/all-MiniLM-L6-v2 ---------\n",
      "model=sentence-transformers/all-MiniLM-L6-v2, created embeddings for 3,403 movies in 14,395 ms, avg_time_per_movie=4 ms\n"
     ]
    }
   ],
   "source": [
    "## For selected embedding models above, we are giong to create vectors\n",
    "## in movie collection.\n",
    "## Remember, each embedding model has its own 'plot_embedding' attribute (we don't want to mix them up)\n",
    "\n",
    "for key in model_mappings.keys():\n",
    "    embedding_model = key\n",
    "    embedding_attr = model_mappings[key]['embedding_attr']\n",
    "\n",
    "    print (f'\\n------- embedding model = {embedding_model} ---------')\n",
    "    t1a = time.perf_counter()\n",
    "    create_embeddings(movies=movies, embedding_model=embedding_model, embedding_attr=embedding_attr)\n",
    "    t1b = time.perf_counter()\n",
    "    avg_time_per_movie = (t1b-t1a)*1000 / len(movies)\n",
    "    print (f'model={embedding_model}, created embeddings for {len(movies):,} movies in {(t1b-t1a)*1000:,.0f} ms, avg_time_per_movie={avg_time_per_movie:,.0f} ms')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-4: Inspect Generated Embeddings\n",
    "\n",
    "Run the cell below a few times to see a different movie each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_id : 573a1396f29313caabce4c51\n",
      "title : All the Way Boys\n",
      "plot : The \"Trinity\" crew makes another modern era film. Plata and Salud are pilots ditching aircraft for insurance money. They wind up crashing for real in the jungles of South America. The plot ...\n",
      "plot_embeddings (existing openAI generated), len=1536 , [-0.0070214528, -0.02774179, 0.0030583397, -0.024975868, -0.007300109]...\n",
      "plot_embedding_bge_small , len=384 , [-0.023717263713479042, 0.0627506896853447, 0.008340640924870968, 0.011099166236817837, 0.12430629134178162]...\n",
      "plot_embedding_mpnet_base_v2 , len=768 , [-0.006945954170078039, -0.021002354100346565, 0.03779927268624306, -0.018684331327676773, 0.06510608643293381]...\n",
      "plot_embedding_minilm_l6_v2 , len=384 , [0.00892637763172388, -0.015575622208416462, -0.03332819417119026, 0.00015540290041826665, 0.059477709233760834]...\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "movie = random.choice(movies)\n",
    "# print (movie)\n",
    "print ('_id :', movie['_id'])\n",
    "print ('title :', movie['title'])\n",
    "print ('plot :', movie['plot'])\n",
    "print (f'plot_embeddings (existing openAI generated), len={len(movie[\"plot_embedding\"])} , {movie[\"plot_embedding\"][:5]}...')\n",
    "print (f'plot_embedding_bge_small , len={len(movie[\"plot_embedding_bge_small\"])} , {movie[\"plot_embedding_bge_small\"][:5]}...')\n",
    "print (f'plot_embedding_mpnet_base_v2 , len={len(movie[\"plot_embedding_mpnet_base_v2\"])} , {movie[\"plot_embedding_mpnet_base_v2\"][:5]}...')\n",
    "print (f'plot_embedding_minilm_l6_v2 , len={len(movie[\"plot_embedding_minilm_l6_v2\"])} , {movie[\"plot_embedding_minilm_l6_v2\"][:5]}...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-5: Now Update Movie Collection in Atlas\n",
    "\n",
    "We have calculated all embeddings locally.\n",
    "\n",
    "Let's update the Atlas database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If we update documents ONE-BY-ONE, it takes about 5 minutes to complete\n",
    "## So this code is not recommended\n",
    "\n",
    "\n",
    "# collection = atlas_client.get_collection(COLLECTION_NAME)\n",
    "\n",
    "# t1a = time.perf_counter()\n",
    "# for movie in movies:\n",
    "# \tcollection.replace_one({'_id': movie['_id']}, movie)\n",
    "# t1b = time.perf_counter()\n",
    "\n",
    "# print (f'Updated {len(movies):,} in Atlas in {(t1b-t1a)*1000:,.0f} ms')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About to update 3403 movies in Atlas...\n",
      "Update matched count: 3403\n",
      "Update modified count: 0\n",
      "Updated 3,403 in Atlas in 70,906 ms\n"
     ]
    }
   ],
   "source": [
    "## Let's do a bulk update\n",
    "from pymongo import  ReplaceOne\n",
    "\n",
    "\n",
    "collection = atlas_client.get_collection(COLLECTION_NAME)\n",
    "\n",
    "replacements = [ReplaceOne ({\"_id\" : movie[\"_id\"]}, movie) for movie in movies]\n",
    "\n",
    "# print (replacements[:3])\n",
    "\n",
    "# Perform bulk replacement\n",
    "print (f'About to update {len(replacements)} movies in Atlas...')\n",
    "t1a = time.perf_counter()\n",
    "result = collection.bulk_write(replacements)\n",
    "t1b = time.perf_counter()\n",
    "\n",
    "## Print result\n",
    "print(f\"Update matched count: {result.matched_count}\")\n",
    "print(f\"Update modified count: {result.modified_count}\")\n",
    "print (f'Updated {len(movies):,} in Atlas in {(t1b-t1a)*1000:,.0f} ms')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-6: Verify Data in Atlas UI\n",
    "\n",
    "Let's see if the embeddings are populuated in Atlas.\n",
    "\n",
    "Go to Atlas UI --> Browse Collections --> sample_mflix --> embedded_movies\n",
    "\n",
    "You should see something like this:\n",
    "\n",
    "![](../images/custom-embeddings-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-7: Create Indexes\n",
    "\n",
    "We need to create indexes on embedding attributes before we query.\n",
    "\n",
    "Refer to this document for detailed steps : [../lab-2-vector-search-openai/setup-atlas-index.md](../lab-2-vector-search-openai/setup-atlas-index.md)\n",
    "\n",
    "Remember, we have a few embeddings, each needs its own index.\n",
    "\n",
    "We have have 3 indices in Atlas in free tier.  So we can create additional 2 indexes. That is perfectly ok for this lab.  You can choose which ones to experiment with.\n",
    "\n",
    "**In Atlas UI, enter the index commands below correctly.  Make sure `path` and `numDimensions` match!**\n",
    "\n",
    "![](../images/atlas-index-5.png)\n",
    "\n",
    "\n",
    "### Embedding-1: `BAAI/bge-small-en-v1.5`\n",
    "\n",
    "Index type: **Atlas Vector Search**\n",
    "\n",
    "Index name: **`idx_plot_embedding_bge_small`**\n",
    "\n",
    "**Index definition**\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"type\": \"vector\",\n",
    "      \"path\": \"plot_embedding_bge_small\",\n",
    "      \"numDimensions\": 384,\n",
    "      \"similarity\": \"euclidean\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "### Embedding-2: `sentence-transformers/all-mpnet-base-v2`\n",
    "\n",
    "Index type: **Atlas Vector Search**\n",
    "\n",
    "Index name: **`idx_plot_embedding_mpnet_base_v2`**\n",
    "\n",
    "**Index definition**\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"type\": \"vector\",\n",
    "      \"path\": \"plot_embedding_mpnet_base_v2\",\n",
    "      \"numDimensions\": 768,\n",
    "      \"similarity\": \"euclidean\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "### (Optional) Embedding-3: `sentence-transformers/all-MiniLM-L6-v2`\n",
    "\n",
    "Index type: **Atlas Vector Search**\n",
    "\n",
    "Index name: **`idx_plot_embedding_minilm_l6_v2`**\n",
    "\n",
    "**Index definition**\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"type\": \"vector\",\n",
    "      \"path\": \"plot_embedding_minilm_l6_v2\",\n",
    "      \"numDimensions\": 384,\n",
    "      \"similarity\": \"euclidean\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-8: Verifying Indexes\n",
    "\n",
    "Make sure indexes are ready and active before proceeding to the next step.\n",
    "\n",
    "![](../images/atlas-index-6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atlas-1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
